# Agent Deen System Architecture

## High-Level Architecture

```mermaid
flowchart TB
    subgraph Frontend["ðŸ–¥ï¸ Frontend (Streamlit)"]
        UI[app.py]
        Chat[Chat Page]
        Sources[Manage Sources]
    end

    subgraph Backend["âš™ï¸ Backend (FastAPI)"]
        API[API Endpoints]
        ChatSvc[ChatService]
        IngestSvc[IngestionService]
        RAG[RAG Pipeline]
    end

    subgraph AI["ðŸ¤– AI Layer"]
        Ollama[Ollama LLM]
        Claude[Claude Haiku]
        Translator[Language Translator]
    end

    subgraph Storage["ðŸ’¾ Storage"]
        Pinecone[(Pinecone Vector DB)]
        PDFs[("data/ PDFs")]
    end

    subgraph Scrapers["ðŸ”§ Scrapers"]
        BNM[BNM Scraper]
        Manual[Manual Scraper]
        Playwright[Playwright WAF Bypass]
    end

    UI --> API
    Chat --> ChatSvc
    Sources --> IngestSvc
    
    ChatSvc --> RAG
    RAG --> Pinecone
    RAG --> Ollama
    RAG --> Claude
    RAG --> Translator
    
    IngestSvc --> Manual
    Manual --> Playwright
    Manual --> PDFs
    IngestSvc --> Pinecone
    
    API --> PDFs
```

## Data Flow: Ask a Question

```mermaid
sequenceDiagram
    participant U as User
    participant S as Streamlit
    participant A as FastAPI
    participant R as RAG Pipeline
    participant P as Pinecone
    participant L as LLM (Ollama/Claude)

    U->>S: Ask question in Malay
    S->>A: POST /chat
    A->>R: query(question)
    R->>R: Detect language (Malay)
    R->>R: Translate to English
    R->>P: Search similar chunks
    P-->>R: Top 5 chunks + metadata
    R->>R: Filter by relevance (>0.65)
    R->>L: Generate answer with context
    L-->>R: Answer in Malay
    R->>R: Ensure language (translate if needed)
    R-->>A: RAGResponse
    A-->>S: JSON response
    S-->>U: Display answer + sources
```

## Data Flow: Ingest Document

```mermaid
sequenceDiagram
    participant U as User
    participant S as Streamlit
    participant A as FastAPI
    participant I as IngestionService
    participant SC as ManualScraper
    participant PW as Playwright
    participant PR as PDF Processor
    participant P as Pinecone

    U->>S: Provide URL or Upload PDF
    S->>A: POST /ingest/url or /ingest/upload
    A->>I: ingest_from_url() or ingest_file()
    
    alt URL Ingestion
        I->>SC: scrape_from_url()
        SC->>PW: Download PDF (WAF bypass)
        PW-->>SC: PDF bytes
        SC->>SC: Save to data/manual/
    else File Upload
        I->>I: Save to data/manual/
    end
    
    I->>PR: extract_text()
    PR-->>I: Text + page numbers
    I->>I: chunk_with_pages()
    I->>I: Generate embeddings (Ollama)
    I->>P: Upsert vectors + metadata
    P-->>I: Success
    I-->>A: {status, pages, chunks}
    A-->>S: JSON response
    S-->>U: Success message
```

## Storage Structure

```
for-ummah/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bnm/                    # BNM scraped PDFs
â”‚   â”‚   â””â”€â”€ *.pdf
â”‚   â”œâ”€â”€ manual/                 # User uploads & URL downloads
â”‚   â”‚   â””â”€â”€ *.pdf
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ all_chunks_with_pages.json  # Local backup
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/main.py             # FastAPI endpoints
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py         # ChatService
â”‚   â”‚   â””â”€â”€ ingestion.py        # IngestionService
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ rag.py              # RAG Pipeline
â”‚   â”‚   â”œâ”€â”€ ollama_llm.py       # Ollama client
â”‚   â”‚   â”œâ”€â”€ claude_llm.py       # Claude client
â”‚   â”‚   â””â”€â”€ translator.py       # Language enforcement
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ base.py             # BaseScraper + Playwright
â”‚   â”‚   â”œâ”€â”€ bnm.py              # BNM website scraper
â”‚   â”‚   â””â”€â”€ manual.py           # User upload scraper
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ pdf.py              # Text extraction
â”‚   â”‚   â””â”€â”€ chunker.py          # Sentence-based chunking
â”‚   â””â”€â”€ vector_db/
â”‚       â””â”€â”€ pinecone.py         # Pinecone client
â”‚
â””â”€â”€ app.py                      # Streamlit frontend
```

## API Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/chat` | POST | Ask a question, get RAG answer |
| `/ingest/url` | POST | Ingest document from URL |
| `/ingest/upload` | POST | Upload and ingest PDF |
| `/pdf/{source}/{filename}` | GET | Serve PDF for viewer |
| `/pdf/list` | GET | List all available PDFs |
| `/health` | GET | Health check |

## Key Components

| Component | File | Purpose |
|-----------|------|---------|
| **RAG Pipeline** | `src/ai/rag.py` | Orchestrates search + LLM |
| **Ingestion** | `src/services/ingestion.py` | PDF processing pipeline |
| **PDF Viewer** | `src/api/main.py` | Serves PDFs with page navigation |
| **Playwright** | `src/scrapers/base.py` | WAF bypass for downloads |
